data_dir: /lustre/fsn1/projects/rech/yjs/umf82pt/LibriSpeech/
exp_dir: exp

anon_data_suffix: _anon_B5 # added to transform data/libri_dev/ to data/libri_dev_mcadams/ with data/libri_dev_mcadams/wav/*wav

train_data_name: !ref LibriSpeech<anon_data_suffix>
model_name: asv_orig
model_type: ecapa


asv:
  model_type: ecapa  # ecapa or xvector
  dataset_name: [libri_dev, libri_test]

  training:
    model_dir: !ref <exp_dir>/asv_anon<anon_data_suffix>  # path to existing ASV model or output for trained ASV model
    train_data_dir: !ref <data_dir>/<train_data_name> # path to original or anonymized training data for ASV
    train_config: asv_training/hparam/train_ecapa_tdnn_small.yaml
    infer_config: asv_training/hparam/hyperparams.yaml
    finetuning: false # true (ft) or false (scratch)
    pretrained_model: null # path to pretrained model, only used for finetuning
    lr: 0.01
    epochs: 100
    batch_size: 256 
    num_workers: 10 #increse this can speed up the training process
    num_utt: ALL  # ALL or specific number, number of utterances per speaker
    utt_selection: spk-diverse-sess  # select utterances per speaker and session (spk-sess), per speaker and randomly across all sessions (spk-random), per speaker and balanced across sessions (spk-diverse-sess)
    num_spk: ALL  # ALL or specific number, number of speakers
    retrain: true  # retrain in any case (true) or skip training if model exists (false)
    save_folder: csv